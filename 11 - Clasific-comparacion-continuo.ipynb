{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Estos dos comandos evitan que haya que hacer reload cada vez que se modifica un paquete\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anotaciones:\n",
    "Desde el lado de Estadistica querriamos ver que tan bueno se aproxima a una gaussiana. Desde ML que tan bien generaliza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/alturas-pesos-mils-train.csv')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/alturas-pesos-mils-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiVariateJoint import BiVariateJoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hombres = data.loc[data['Genero']=='Hombre'][['Peso','Altura']].values\n",
    "data_mujeres = data.loc[data['Genero']=='Mujer'][['Peso','Altura']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Gaussiano (Quadratic Discriminant Analisys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "peso_altura_hombres = data.loc[data['Genero']=='Hombre'][['Peso', 'Altura']].values\n",
    "peso_altura_mujeres = data.loc[data['Genero']=='Mujer'][['Peso', 'Altura']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hombres = peso_altura_hombres.mean(axis=0)\n",
    "mean_mujeres = peso_altura_mujeres.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_hombres = np.cov(peso_altura_hombres.T)\n",
    "cov_mujeres = np.cov(peso_altura_mujeres.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gauss_prob(data, mean_hombres, mean_mujeres, cov_hombres, cov_mujeres):\n",
    "    data_np = data\n",
    "    likelihood_class_1 = multivariate_normal.pdf(data_np, mean_hombres, cov_hombres)\n",
    "    likelihood_class_2 = multivariate_normal.pdf(data_np, mean_mujeres, cov_mujeres)\n",
    "    N_class_1 = len(peso_altura_hombres)\n",
    "    N_class_2 = len(peso_altura_mujeres)\n",
    "    prior_1 = N_class_1/(N_class_1 + N_class_2)\n",
    "    prior_2 = N_class_2/(N_class_1 + N_class_2)\n",
    "    total = likelihood_class_1 * prior_1 + likelihood_class_2 * prior_2\n",
    "    p_class_1 = likelihood_class_1 * prior_1/total\n",
    "    p_class_2 = likelihood_class_2 * prior_2/total\n",
    "    return p_class_1, p_class_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_gauss(data, mean_hombres, mean_mujeres, cov_hombres, cov_mujeres):\n",
    "    p_class_1, p_class_2 = get_gauss_prob(data[['Peso', 'Altura']].values, mean_hombres, mean_mujeres, cov_hombres, cov_mujeres)\n",
    "    return ((p_class_1>p_class_2)==(data['Genero']=='Hombre')).sum()/len(p_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9167395924490561\n"
     ]
    }
   ],
   "source": [
    "acc_QDA_train = get_acc_gauss(data, mean_hombres, mean_mujeres, cov_hombres, cov_mujeres)\n",
    "print(acc_QDA_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9225\n"
     ]
    }
   ],
   "source": [
    "acc_QDA_CV = get_acc_gauss(test, mean_hombres, mean_mujeres, cov_hombres, cov_mujeres)\n",
    "print(acc_QDA_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hombres = peso_altura_hombres.mean(axis=0)\n",
    "mean_mujeres = peso_altura_mujeres.mean(axis=0)\n",
    "cov_LDA = np.cov(np.vstack([peso_altura_hombres - mean_hombres, peso_altura_mujeres - mean_mujeres]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9167395924490561\n"
     ]
    }
   ],
   "source": [
    "acc_LDA_train = get_acc_gauss(data, mean_hombres, mean_mujeres, cov_LDA, cov_LDA)\n",
    "print(acc_LDA_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9225\n"
     ]
    }
   ],
   "source": [
    "acc_LDA_CV = get_acc_gauss(test, mean_hombres, mean_mujeres, cov_LDA, cov_LDA)\n",
    "print(acc_LDA_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_hombres_nb = np.cov(peso_altura_hombres.T)*np.identity(2)\n",
    "cov_mujeres_nb = np.cov(peso_altura_mujeres.T)*np.identity(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_naive(data):\n",
    "    data_np = data\n",
    "    likelihood_class_1 = multivariate_normal.pdf(data_np, mean_hombres, cov_hombres*np.identity(2))\n",
    "    likelihood_class_2 = multivariate_normal.pdf(data_np, mean_mujeres, cov_mujeres*np.identity(2))\n",
    "    N_class_1 = len(peso_altura_hombres)\n",
    "    N_class_2 = len(peso_altura_mujeres)\n",
    "    prior_1 = N_class_1/(N_class_1 + N_class_2)\n",
    "    prior_2 = N_class_2/(N_class_1 + N_class_2)\n",
    "    total = likelihood_class_1 * prior_1 + likelihood_class_2 * prior_2\n",
    "    p_class_1 = likelihood_class_1 * prior_1/total\n",
    "    p_class_2 = likelihood_class_2 * prior_2/total\n",
    "    return p_class_1, p_class_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_gauss_naive(data):\n",
    "    p_class_1, p_class_2 = get_prob_naive(data[['Peso', 'Altura']].values)\n",
    "    return ((p_class_1>p_class_2)==(data['Genero']=='Hombre')).sum()/len(p_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8869858732341542\n"
     ]
    }
   ],
   "source": [
    "acc_NB_train = get_acc_gauss_naive(data)\n",
    "print(acc_NB_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887\n"
     ]
    }
   ],
   "source": [
    "acc_NB_CV = get_acc_gauss_naive(test)\n",
    "print(acc_NB_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_Reg.fit(data[['Peso', 'Altura']].values, data['Genero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166145768221028\n"
     ]
    }
   ],
   "source": [
    "acc_LR_train = log_Reg.score(data[['Peso', 'Altura']].values, data['Genero'])\n",
    "print(acc_LR_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922\n"
     ]
    }
   ],
   "source": [
    "acc_LR_CV = log_Reg.score(test[['Peso', 'Altura']].values, test['Genero'])\n",
    "print(acc_LR_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "X = np.linspace(data.min()['Peso'], data.max()['Peso'], N)\n",
    "Y = np.linspace(data.min()['Altura'], data.max()['Altura'], N)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "# Pack X and Y into a single 3-dimensional array\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X\n",
    "pos[:, :, 1] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_H = multivariate_normal.pdf(pos, mean_hombres, cov_hombres)\n",
    "Z_M = multivariate_normal.pdf(pos, mean_mujeres, cov_mujeres)\n",
    "Z_gaus, _ = get_gauss_prob(pos, mean_hombres, mean_mujeres, cov_hombres, cov_mujeres)\n",
    "\n",
    "Z_H_LDA = multivariate_normal.pdf(pos, mean_hombres, cov_LDA)\n",
    "Z_M_LDA = multivariate_normal.pdf(pos, mean_mujeres, cov_LDA)\n",
    "Z_LDA, _ = get_gauss_prob(pos, mean_hombres, mean_mujeres, cov_LDA, cov_LDA)\n",
    "\n",
    "Z_H_nb = multivariate_normal.pdf(pos, mean_hombres, cov_hombres*np.identity(2))\n",
    "Z_M_nb = multivariate_normal.pdf(pos, mean_mujeres, cov_mujeres*np.identity(2))\n",
    "Z_nb, _ = get_prob_naive(pos)\n",
    "\n",
    "Z_lr = log_Reg.predict_proba(np.c_[X.ravel(), Y.ravel()])[:, 0]\n",
    "Z_lr = Z_lr.reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundAcc(acc):\n",
    "    return str(np.round(acc*100)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "alpha = 0.5\n",
    "f, ax = plt.subplots(2,2, figsize=(20,10))\n",
    "ax = ax.reshape(-1)\n",
    "cm = plt.cm.RdBu\n",
    "cf = ax[0].contourf(X, Y, Z_gaus, 256, alpha=.8, vmin=0., vmax=1., cmap=cm)\n",
    "ax[0].contour(X, Y, Z_gaus, (0.5,), colors='k', linewidths=1)\n",
    "ax[0].set_title(\"QDA - Train: \" + roundAcc(acc_QDA_train) + \" CV: \" + roundAcc(acc_QDA_CV))\n",
    "ax[1].contourf(X, Y, Z_LDA, 256, alpha=.8, vmin=0., vmax=1., cmap=cm)\n",
    "ax[1].contour(X, Y, Z_LDA, (0.5,), colors='k', linewidths=1)\n",
    "ax[1].set_title(\"LDA - Train: \" + roundAcc(acc_LDA_train) + \" CV: \" + roundAcc(acc_LDA_CV))\n",
    "ax[2].contourf(X, Y, Z_nb, 256, alpha=.8, vmin=0., vmax=1., cmap=cm)\n",
    "ax[2].contour(X, Y, Z_nb, (0.5,), colors='k', linewidths=1)\n",
    "ax[2].set_title(\"Naive Bayes - Train: \" + roundAcc(acc_NB_train) + \" CV: \" + roundAcc(acc_NB_CV))\n",
    "ax[3].contourf(X, Y, Z_lr, 256, alpha=.8, vmin=0., vmax=1., cmap=cm)\n",
    "ax[3].contour(X, Y, Z_lr, (0.5,), colors='k', linewidths=1)\n",
    "ax[3].set_title(\"Regresión Logística - Train: \" + roundAcc(acc_LR_train) + \" CV: \" + roundAcc(acc_LR_CV))\n",
    "\n",
    "plt.colorbar(cf, ax=ax)\n",
    "z_levels = np.logspace(-5,-2,10)/4\n",
    "for a in ax:\n",
    "    a.scatter(data_hombres[:,0], data_hombres[:,1], color='b', s=2, alpha=alpha)\n",
    "    a.scatter(data_mujeres[:,0], data_mujeres[:,1], color='r', s=2, alpha=alpha)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.gca()\n",
    "cm = plt.cm.RdBu\n",
    "# cf = ax.contourf(X, Y, Z_lr, 256, alpha=.5, vmin=0., vmax=1., cmap=cm)\n",
    "cs1 = ax.contour(X, Y, Z_lr, (0.5,), colors='b', linewidths=1)\n",
    "cs2 = ax.contour(X, Y, Z_gaus, (0.5,), colors='g', linewidths=1)\n",
    "cs3 = ax.contour(X, Y, Z_nb, (0.5,), colors='r', linewidths=1)\n",
    "cs4 = ax.contour(X, Y, Z_LDA, (0.5,), colors='k', linewidths=1)\n",
    "#ax.contour(X, Y, Z_H, z_levels, linewidths=0.5)\n",
    "#ax.contour(X, Y, Z_M, z_levels, linewidths=0.5)\n",
    "plt.scatter(data_hombres[:,0], data_hombres[:,1], color='b', s=2, alpha=0.5)\n",
    "plt.scatter(data_mujeres[:,0], data_mujeres[:,1], color='r', s=2, alpha=0.5)\n",
    "ax.set_ylabel('Alturas [cms]')\n",
    "ax.set_xlabel('Pesos [kgs]')\n",
    "cs1.collections[0].set_label(\"Regresión Logística\")\n",
    "cs2.collections[0].set_label(\"Bayes Gaussiano\")\n",
    "cs3.collections[0].set_label(\"Naive Bayes Gaussiano\")\n",
    "cs4.collections[0].set_label(\"LDA\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "cm = plt.cm.RdBu\n",
    "ax.contourf(X, Y, Z_nb, 256, vmin=0., vmax=1., cmap=cm)\n",
    "ax.contourf(X, Y, Z_gaus, 256, vmin=0., vmax=1., cmap=cm)\n",
    "# ax.set_title('TRAIN: ' + str(np.round(acc_train_LR*100)/100) + ' - CV:' + str(np.round(acc_CV_LR*100)/100))\n",
    "ax.set_ylabel('Alturas [cms]')\n",
    "ax.set_xlabel('Pesos [kgs]')\n",
    "ax.view_init(70, -90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9167395924490561,\n",
       " 0.9225,\n",
       " 0.8869858732341542,\n",
       " 0.887,\n",
       " 0.9167395924490561,\n",
       " 0.9225,\n",
       " 0.9166145768221028,\n",
       " 0.922)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_QDA_train, acc_QDA_CV, acc_NB_train, acc_NB_CV, acc_LDA_train, acc_LDA_CV, acc_LR_train, acc_LR_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8000 ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Modelo| tipo| Train Acc| CV Acc|Comentarios\n",
    "|-| -| -| -|-|\n",
    "|Gaussian|Bayes|0.92|0.92|\n",
    "|Gaussian|Naive Bayes|0.89|0.89|\n",
    "|LDA|-|0.92|0.92|\n",
    "|Regresion Logística|-|0.92|0.92|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100 ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Modelo| tipo| Train Acc| CV Acc|Comentarios\n",
    "|-| -| -| -|-|\n",
    "|Gaussian|Bayes|0.90|0.90|\n",
    "|Gaussian|Naive Bayes|0.89|0.89|\n",
    "|LDA|-|0.87|0.91|\n",
    "|Regresion Logística|-|0.87|0.91|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
